<!DOCTYPE html>
<html>
<head>
<meta name="viewport" content="width=device-width, initial-scale=1">
<style>
body {
  margin: 0;
  font-family: Arial, Helvetica, sans-serif;
}

.topnav {
  overflow: hidden;
  background-color: #333;
}

.topnav a {
  float: left;
  color: #f2f2f2;
  text-align: center;
  padding: 14px 16px;
  text-decoration: none;
  font-size: 17px;
}

.topnav a:hover {
  background-color: #ddd;
  color: black;
}

.topnav a.active {
  background-color: #04AA6D;
  color: white;
}
</style>
</head>
<body>

<div class="topnav">
  <h1 style="text-align:center; color:white;">Applying CTML and CLT to design a platform for Multimedia Music Learning</h1>.
  </br>
  <a href="index.html">Introduction</a>
  <a href="definitions.html">Definitions</a>
  <a href="goals.html">Goals</a>
  <a href="specifications.html">Specifications</a>
  <a class="active" href="interpreting.html">Interpreting CTML</a>
  <a href="design-choices.html">Design Choices</a>
  <a href="mockups.html">Mockups</a>
  <a href="references.html">References</a>
  <p style="text-align:right; color:white; padding-right:25px">by Josh Milton</p>
</div>

<div style="padding-left:10%; padding-right:10%; text-align:left;">

  <h2 style ="text-align: center;">CTML Principles</h2>
  <p>Mayer’s CTML (2014) describes a series of principles which can be used as a guide for creating effective multimedia learning materials. While most of these principles are clearly applicable to learning within the field of music, others require a deeper exploration and understanding of cognitive processing to interpret their application to music learning.</p>
  <p>Before trying to interpret each of these principles we must first take a step back and try to understand how music, specifically audio and notation stimuli, relates to the Dual-Coding foundations of CTML. As well as adjacent theories like Cognitive Learning Theory (Sweller, 1998). </p>
  <br>
  <br>
  <h2 style ="text-align: center;">Dual-Coding Theory?</h2>
  <p>Looking again at Mayer’s Dual-Coding Theory (See Figure 5), we can see that no input is accounted for within the auditory processing channel other than that of spoken word – the role of musical sound within CTML is typically relegated to that of extraneous background music (Moreno & Mayer, 2000) and thus has not been considered as an essential stimulus.</p>
  <div align = "center";>  <img src="img/Fig5.png">
    <p><b>Figure 5:</b> The CTML Dual-Coding Theory (Mayer, 2014)</p>
    </div>
  <p>Peretz (2001) suggests that entirely distinct components of the brain are used for processing musical cues than verbal information, indicating that these can be discriminated aurally by trained musicians within the selection and organisation phases of the working and sensory memories. This idea that music is processed discretely from verbal sound is supported by literature on working memory and cognitive load relating to music (Berz, 1995; Owens & Sweller, 2008), though still contributing to overall cognitive load. This is not necessarily to the detriment of instruction involving spoken word and music, as Ahmad Aldalalah and Fook Fong (2010) suggest that total cognitive load and working memory capacity may be higher in those with musical training.</p>
  <br>
  <div align = "center";>  <img src="img/Fig6.png">
    <p><b>Figure 6:</b> A distinct Music model alongside the Verbal model in a larger Aural model of working memory</p>
  </div>
  <br>
  <p>Figure 6 showcases the ideas of Peretz (2001), Berz (1995) and Owens and Sweller (2008) as applied to the CTML Dual-Coding model, with separation of musical cues processed separately in working memory before being organised into a discrete Music Model within a larger Aural model.</p>

</div>

</body>
</html>